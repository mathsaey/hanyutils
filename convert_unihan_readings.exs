#!/usr/bin/env elixir

# Script to convert the Unihan_Readings.txt file from the Unicode Character Database into a file
# that can be parsed by the Hanzi module. We do this upfront instead of at compile time to avoid
# adding the (rather large) Unihan_Readings.txt file to the repository.
#
# Usage: convert_unihan_readings.exs input [output]
#   `input` should be a Unihan_Readings.txt file.
#   `output` can be any file (relative to cwd), it defaults to lib/hanzi/characters.map
#
# The Unihan_Readings.txt file can be found inside a zip archive that can be download here:
# https://www.unicode.org/Public/UCD/latest/ucd/Unihan.zip.
# Documentation for this file can be found here:
# https://www.unicode.org/reports/tr38/

# The Hanzi module expects a file with the following layout:
# - Any line that is not an entry is empty or starts with #
# - Every entry starts with a character followed by the type of entry
# - 'p' entries contain the most common pronunciation of the character. If the most common
#   pronunciation is different for mainland China and Taiwan two pinyin entries can be found here.
# - An 'a' entry contains any "alternative" readings for the character.
# - 'a' and 'p' entries of the same character should be grouped together I.e. if a character has
#   both an 'a' and a 'p' entry, they should be on consecutive lines.

header = """
# Character to pinyin mappings.
# Automatically generated by "convert_unihan_readings.exs".
#
# Copyright of the original file applies.
# The following is the header of the original file, which should include a
# copyright notice.
"""

delimiter = """
# =============================================================================
"""

# Get Paths & stream file
{in_path, out_path} = case System.argv() do
  [i, o] ->
    {Path.expand(i), Path.expand(o)}
  [i] ->
    {Path.expand(i), Path.join(__DIR__, "lib/hanzi/characters.map")}
  _ ->
    script = Path.relative_to_cwd(__ENV__.file)
    IO.puts "Invalid arguments. Usage: `elixir #{script} input [output]`"
    System.halt(1)
end

stream = File.stream!(in_path)

# Create the header stream
is_header? = &String.starts_with?(&1, ["#", "\n"])
original_header = stream |> Stream.take_while(is_header?)
header = Stream.concat([[header, delimiter], original_header, [delimiter]])

# Create the body stream
body = stream |> Stream.drop_while(is_header?)

body =
  body
  |> Stream.filter(&String.contains?(&1, ["kMandarin", "kHanyuPinyin"]))
  |> Stream.map(&String.split/1)
  # charcode to character
  |> Stream.map(fn [code | rest] ->
    char = code |> String.trim_leading("U+") |> String.to_integer(16)
    [<< char :: utf8 >> | rest]
  end)
  # Process entries
  |> Stream.map(fn
    [code, "kHanyuPinyin" | entries] ->
      entry =
        entries
        |> Enum.map(fn entry ->
          [_, entry] = String.split(entry, ":")
          String.split(entry, ",")
        end)
        |> Enum.concat()
        |> Enum.uniq()

      [code, "a" | entry]

    [code, "kMandarin" | entries] ->
      [code, "p" | entries]

  end)

  |> Stream.map(&Enum.join(&1," "))
  |> Stream.map(&(&1 <> "\n"))

# Write output file
Stream.concat(header, body)
|> Stream.into(File.stream!(out_path))
|> Stream.run()
